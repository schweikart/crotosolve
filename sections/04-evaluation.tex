\chapter{Evaluation}
\label{chap:evaluation}

To evaluate the quality of the algorithm proposed in chapter
\ref{chap:gradient-free}, we implement a proof-of-concept optimizer.
We compare our optimizer to a number of other optimizers frequently used in QML
by creating a loss curve benchmark for all optimizers.
The benchmark features parameterizable quantum circuits with various degrees of
expressibility and from various research applications.

\section{Proof of Concept}
To put the approach proposed in chapter \ref{chap:gradient-free} to test,
we implement a proof-of-concept application with PennyLane
\cite{bergholm_pennylane_2022}.
PennyLane is a popular \cite{unitary_fund_team_results_2022} quantum computing
SDK with extensive documentation and a number of QML optimizers already
implemented.
Particularly, PennyLane is currently the only quantum SDK to implement the
\texttt{Rotosolve} optimizer, to which we want to compare our optimizer in
section \ref{sec:optimizer-comparison}.

While the circuits we want to optimize can be composed of arbitrary static
(i.e., non-parameterized) gates, we limit the types of parameterizable gates to
rotational pauli gates and controlled rotational pauli gates.
Additionally, we assume all parameters are independent from each other and used
without any preprocessing (e.g., having a $RP(x^2)$ gate for a parameter $x$).
% TODO comment on whether this is an actual limitation?

For our algorithm to work, we also need to know which parameters belong to which
type of parameterized gate.
As a simple solution, we assume all $RP$ parameters are passed as an array
separate from the $CRP$ parameters array.
It is in theory, however, also possible to detect the type of gate through static analysis
of the circuit, which is beyond the scope of this thesis.

Similar to the \texttt{Rotosolve} algorithm \cite{ostaszewski_structure_2021},
our \texttt{Crotosolve} implementation optimizes each parameter individually.
Each parameter corresponding to an uncontrolled rotational pauli gate can be
optimized following the exact approach presented by Ostaszewski et al..
And for each parameter corresponding to a controlled rotational pauli gate, we
first reconstruct the univariate cost function (see section \ref{sec:constants})
and then use a numerical optimizer to find the minimizing parameter value (see
section \ref{sec:minimization}).
The algorithm pseudocode is stated in listing \ref{alg:crotosolve}.

\begin{algorithm}
    \caption{The \texttt{Crotosolve} algorithm updates parameter individually}
    \label{alg:crotosolve}
    %
    \SetKwFunction{ReconstructCrp}{ReconstructCrp}
    \SetKwFunction{RotosolveUpdate}{RotosolveUpdate}
    \SetKwFunction{MakeUnivariate}{MakeUnivariate}
    %
    \KwData{$prev\_params \in \mathbb R^n$, $circuit$}
    \KwResult{$params \in \mathbb R^n$}
    \BlankLine
    $params \gets copy(prev\_params)$\;
    \For{$p \gets 1$ \KwTo $n$}{
        $uni \gets $ \MakeUnivariate{$circuit$, $params$, $p$}\;
        \eIf{$p$ belongs to controlled gate}{
            $recon \gets $ \ReconstructCrp{$uni$} \Comment*[r]{see section \ref{sec:constants}}
            $next\_params[p] \gets \underset{x \in [0, 4\pi]}{\operatorname{argmin}}\, recon(x)$ \Comment*[r]{using numerical minimizer}
        }{
            $next\_params[p] \gets $ \RotosolveUpdate{$uni$}\;
        }
    }
\end{algorithm}

\section{Optimizer comparison}
\label{sec:optimizer-comparison}
\subsubsection*{Methodology}

We want to examine \texttt{Crotosolve}'s performance by comparing its loss curve
with state-of-the-art QML optimizers.
This comparison includes the Gradient Descent family of optimizers, namely
standard gradient descent with a fixed learning rate, % TODO: cite! and isnt this really stochastic GD?
\texttt{Adam} \cite{kingma_adam_2017} and
\texttt{Adagrad} \cite{duchi_adaptive_2011}.
Additionally, we test our \texttt{Crotosolve} implementation against PennyLane's
implementation of the \texttt{Rotosolve} algorithm
\cite{ostaszewski_structure_2021,bergholm_pennylane_2022}, which is extended by
Wierich's paper on ``General parameter-shift rules for quantum gradients'' to
support further types of gates \cite{wierichs_general_2022}.

To get meaningful results, we chose to look at loss curves of these optimizers
when applied to well-known and widely-used quantum circuits.
Here, we use the set of circuit templates presented in a paper on
``Expressibility and Entangling Capability [...]'' metrics by Sukin Sim et al.
\cite{sim_expressibility_2019}.
As shown in this paper, these circuits have various degrees of expressibility
and entangling capability. % TODO why is that good
% TODO mention that this set of circuits has also been used as a benchmark in
%      other cases

To reduce statistical noise, we generate random initial parameter values
for all evaluated circuits and run each optimizer several times for each pair
of circuit and initial state.
These runs are then averaged and the average loss curves from various optimizers
are combined within a chart for each combination.
% TODO: is this clear enough
Note that we record the loss curve with respect to the number of circuit
evaluations, not the number of iterations or time taken to optimize a circuit's
parameters.
While time is the metric that will be the most interesting long-term,
today's quantum devices and simulators vary heavily in this regard.
For example, gradient-based optimizers benefit from PennyLanes gradient
evaluation optimizations which won't be available on real quantum hardware.
% TODO: cite!
Meanwhile, gradient-free optimizers like \texttt{Crotosolve} and
\texttt{Rotosolve} can't take advantage of these simulation tricks.
Iterations, on the other hand, put both \texttt{Crotosolve} and
\texttt{Rotosolve} in favor since they have to optimize each parameter
individually within each iteration step, which is much more computational work
than a single gradient descent step regardless of the execution environment.
Circuit evaluations, however, are proportional to the execution time on real
quantum hardware as long as the classical work required between evaluations is
negligible.

% TODO describe the device this has been run on

\subsubsection*{Results}

Figure X shows an example loss curve chart, featuring the average results of all
optimizers for a random circuit Y instance. % TODO mention actual numbers
This chart has been selected as it shows all key characteristics described in
the following but many more of these charts can be found in the appendix.
% TODO actually put them in the appendix
% TODO this sounds a lot like results were selected, emphasis should be on this
%      chart showing ALL characterists that can also be found in other charts

Comparison to gradient-based optimizers: 



\subsubsection*{Discussion}

\begin{itemize}
    \item mention complexity, compare number of evaluations
\end{itemize}

\section{Outline}
\begin{itemize}
    \item
        Evaluate the accuracy of the model, the number of steps in the
        optimization loop and the number of circuit evaluations
        \cite{wendenius_gradient-free_2023,ostaszewski_structure_2021}.
    \item
        Compare the results with the performance of other established
        optimizers (e.g., Adam \cite{kingma_adam_2017}, Gradient Descent and
        Quantum Natural Gradient \cite{stokes_quantum_2020}) as well as the
        \emph{Sine Exact} and \emph{Sine Iterative} variants proposed in
        \cite{wendenius_gradient-free_2023}.
        % TODO: sources for other optimizers
        For this purpose, evaluate at least the circuits from
        \cite{sim_expressibility_2019} that were also evaluated in the
        Wendenius et al. paper \cite{wendenius_gradient-free_2023}.
        % TODO: more circuits to evaluate? eileen might have access to
        %       something...
    \item
        Think about the effects of barren plateaus on this optimizer.
        % TODO: do think about this and come up with a concrete task!
        % TODO: cite barren plateaus
\end{itemize}
